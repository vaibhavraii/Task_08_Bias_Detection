# ğŸ§  Task_08_Bias_Detection

**Research Task 08 â€” Detecting Bias in LLM-Generated Data Narratives**  
Syracuse University | Faculty Sponsor: Jonathan Stromer-Galley  
**Date:** November 1, 2025  

---

## ğŸ“˜ Overview
This project investigates whether large language models (LLMs) like GPT-4, Claude, and Gemini produce biased data narratives when analyzing the same dataset under different prompt framings.

---

## ğŸ§© Objective
To determine how **framing**, **demographic cues**, and **question wording** affect model-generated outputs.

---

## âš™ï¸ How to Run

### 1ï¸âƒ£ Setup
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 2ï¸âƒ£ Generate Prompts
```bash
python scripts/experiment_design.py
```

### 3ï¸âƒ£ Run Experiments
```bash
python scripts/run_experiment.py
```
Paste model responses when prompted. Each response will be stored in `results/responses.jsonl`.

### 4ï¸âƒ£ Validate Results
```bash
python analysis/validate_claims.py
```

### 5ï¸âƒ£ Analyze Bias Patterns
```bash
python analysis/analyze_bias.py
```

---

## ğŸ§® Dataset
Synthetic data of **100 anonymized players** with:
- Goals (10â€“50)
- Assists (5â€“40)
- Turnovers (5â€“30)
- Year Level (Freshmanâ€“Senior)

No personal or real data is used.

---

## ğŸ§  Hypotheses
1. Positive vs. negative framing affects recommendations.  
2. Mentioning year level biases focus to specific groups.  
3. "What went wrong" vs. "What opportunities exist" alters sentiment.  
4. Wording influences whether goals or turnovers are emphasized.

---

## ğŸ“ˆ Files Summary
| Folder | Purpose |
|---------|----------|
| `data/` | Synthetic datasets |
| `prompts/` | Prompt templates for experiments |
| `scripts/` | Automation scripts for design & collection |
| `analysis/` | Code for bias validation and metrics |
| `results/` | Stores logged model responses |
| `REPORT_Progress_Nov1.md` | Current progress report |

---

## ğŸ”’ Notes
- All data is synthetic (no PII).  
- Each experiment logs: timestamp, model, version, and prompt condition.  
- Use consistent parameters (temperature = 0.2) for fairness.

---


